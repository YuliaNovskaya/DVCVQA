{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download videos from youtube, form the list of downloader videos to video_id_train.txt\n",
    "import os\n",
    "import json\n",
    "import pafy\n",
    "\n",
    "# specify download directory\n",
    "directory = '/home/yulia/github/Project_DVCVQA_ver1/helping/download_videos_train_full/'\n",
    "resFile_video = '/home/yulia/github/Activity_net_whole/train_qa.json'\n",
    "ques_video = '/home/yulia/github/Activity_net_whole/activitynet-qa/dataset/train_q10.json'\n",
    "quesFile = '/home/yulia/github/Activity_net_whole/train10_qa_questions.json'\n",
    "data = json.load(open(resFile_video))\n",
    "vid_to_ques_id = data['question']\n",
    "\n",
    "ques_data = json.load(open(quesFile))\n",
    "ques_info_data = json.load(open(ques_video))\n",
    "\n",
    "\n",
    "videoCounter = 0\n",
    "\n",
    "# these lists will record unavailable videos by their key so we can find them \n",
    "# in the downloaded files. it's important to remove these fake files from \n",
    "# datset files for proper training.\n",
    "unavailable_tr = []\n",
    "unavailable_tst = []\n",
    "unavailable_val = []\n",
    "\n",
    "# open json file\n",
    "with open('/home/yulia/github/Activity_net_whole/ActivityNet/activity_net.v1-3.min.json') as data_file:    \n",
    "    data = json.load(data_file)\n",
    "\n",
    "videos = data['database']\n",
    "video_id_train = open(\"video_id_train_full.txt\",\"r\") \n",
    "# take only video informations from database object\n",
    "not_downloaded = open(\"not_downloaded.txt\",\"a\") \n",
    "\n",
    "# print(len(vid_to_ques_id.keys()))\n",
    "\n",
    "for key in vid_to_ques_id.keys():\n",
    "    \n",
    "# iterate through dictionary of videos\n",
    "# for key in videos:\n",
    "    # take video\n",
    "    video_id = key[2:]\n",
    "    video_data = videos[video_id]\n",
    "    \n",
    "#     # find video subset\n",
    "    subset = video_data['subset']\n",
    "\n",
    "#     # find video label\n",
    "    annotations = video_data['annotations']\n",
    "#     print(video_id)\n",
    "    \n",
    "    label = ''\n",
    "    if len(annotations) != 0:\n",
    "        label = annotations[0]['label']\n",
    "        label = '/' + label.replace(' ', '_')\n",
    "\n",
    "#     # create folder named as <label> if does not exist\n",
    "#     label_dir = directory + subset + label\n",
    "#     if not os.path.exists(label_dir):\n",
    "#         os.makedirs(label_dir)\n",
    "\n",
    "    # take url of video\n",
    "    url = video_data['url']\n",
    "    \n",
    "    try:\n",
    "        # start to download\n",
    "        video = pafy.new(url)\n",
    "        best = video.getbest()     \n",
    "        filename = best.download(filepath=directory + '/' + video_id + '.avi')\n",
    "        print('Downloading... ' + str(videoCounter) + '\\n')\n",
    "        videoCounter += 1\n",
    "        \n",
    "    except Exception as inst:\n",
    "        not_downloaded.write(key + \"\\n\") \n",
    "        \n",
    "        if subset == 'training':\n",
    "            unavailable_tr.append(key)\n",
    "            print('Number of Unavailable Training Videos: ',len(unavailable_tr))\n",
    "            print('URL: ', url)\n",
    "            \n",
    "        if subset == 'validation':\n",
    "            unavailable_val.append(key)\n",
    "            print('Number of Unavailable Validation Videos: ', len(unavailable_val))\n",
    "            print('URL: ', url)\n",
    "            \n",
    "        if subset == 'testing':\n",
    "            unavailable_tst.append(key)\n",
    "            print('Number of Unavailable Testing Videos: ', len(unavailable_tst))\n",
    "            print('URL: ', url)\n",
    "            \n",
    "video_id_train.close()\n",
    "not_downloaded.close()        \n",
    "# overall unavailable videos\n",
    "print('Number of Unavailable training videos: ',len(unavailable_tr))\n",
    "print('Number of Unavailable validation videos: ',len(unavailable_val))\n",
    "print('Number of Unavailable testing videos: ',len(unavailable_tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import operator\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "resFile_video = '/home/yulia/github/Activity_net_whole/train_qa.json'\n",
    "quesFile = '/home/yulia/github/Activity_net_whole/train10_qa_questions.json'\n",
    "# ques_video = '/home/yulia/github/Activity_net_whole/train_q10.json'\n",
    "ques_video = '/home/yulia/github/Activity_net_whole/activitynet-qa/dataset/train_q10.json'\n",
    "\n",
    "data = json.load(open(resFile_video))\n",
    "ques_data = json.load(open(quesFile))\n",
    "ques_info_data = json.load(open(ques_video))\n",
    "\n",
    "vid_to_ques_id = data['question']\n",
    "question_id_dict = data['question_id']\n",
    "answer_dict = data['answer_info']\n",
    "question_info = data['question_info']\n",
    "caption_info = data['caption_info']\n",
    "\n",
    "video_id_train = open(\"video_id_train_full.txt\",\"a\") \n",
    "for video_id in caption_info.keys():\n",
    "    video_id_train.write(video_id + \"\\n\") \n",
    "\n",
    "video_id_train.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
